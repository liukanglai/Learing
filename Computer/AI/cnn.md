# 使用 CNN 实现图像分类——理解卷积神经网络（卷积、池化、全连接）

1. 卷积神经网络（CNN）简介

- 19 世纪 60 年代，科学家通过对猫的视觉皮层细胞研究发现，每一个视觉神经元只会处理一小块区域的视觉图像，即感受野（Receptive Field）。卷积神经网络的概念即出自于此。简单说这样做保留了图像的空间信息。

- 2012 年是卷积神经网络崛起之年。这一年，Alex Krizhevsky 带着卷积神经网络参加了 ImageNet 竞赛（其重要程度相当于奥运会）并一鸣惊人，将识别错误率从 26%降到了 15%。

- 从那开始，很多公司开始使用深度学习作为他们服务的核心。比如，Facebook 在他们的自动标记算法中使用了它，Google 在照片搜索中使用了，Amazon 在商品推荐中使用，Printerst 应用于为他们的家庭饲养服务提供个性化定制，而 Instagram 应用于他们的搜索引擎。

为什么 CNN 比普通的神经网络效果更好呢？

2. 卷积神经网络的结构

2.1 卷积

- 卷积是指向图像应用滤波器（Kernel）的过程，通过在原始图像上平移来提取特征。

- 以图片处理为例子，卷积使得神经网络不再仅对一个像素点处理，而是对一小块儿区域进行处理。这种做法，使得神经网络可以看到图形，而不是某一个点，从而加深了对图片的理解。

- 在卷积神经网络中，一个卷积层可以有多个不同的卷积核（也可以说是滤波器），而每个卷积核在输入图像上滑动且每次只处理一小块图像。这样输入端的卷积层可以提取到图像中最基础的特征，比如不同方向的直线或者拐角；接着再组合成高阶特征，比如三角形、正方形等；再继续抽象组合，得到眼睛、鼻子和嘴等五官；最后再将五官组合成一张脸，完成匹配识别。即每个卷积层提取的特征，在后面的层中都会抽象组合成更高阶的特征。

- 卷积层有两个特点：局部连接（Local Connection）和权值共享（Weight Sharing）。局部连接：每个神经元只与上一层的一个局部区域连接，该连接的空间大小叫做神经元的感受野（receptive field）。权值共享：当前层在深度方向上每个 channel 的神经元都使用同样的权重和偏差。局部连接和权值共享降低了参数量，使训练复杂度大大下降，并减轻了过拟合。同时权值共享还赋予了卷积网络对平移的容忍性。

  2.2 池化（降采样）（子采样）

- 池化（pooling）是对图片进行压缩（降采样）的一种方法。

- 池化主要的作用是压缩数据和参数的量（保持最显著的特征），通过去掉 Feature Map 中不重要的样本，进一步减少参数数量。Pooling 的方法很多，通常采用最大池化。

- 最大池化可以使得 CNN 具备一定的旋转不变性

  2.3 分类/全连接（FC, Full Connection）

- 前面的卷积和池化相当于做特征工程，最后的全连接层在整个卷积神经网络中起到“分类器”的作用。

- 如果 FC 层作为最后一层，再加上 softmax 或者 wx+b，则可以分别作为分类或回归的作用，即“分类器”或“回归器”的作用

- 如果作为倒数第 2，3 层的话，FC 层的作用是信息融合，增强信息表达。

3. 搭建 CNN 结构

比较流行的一种搭建结构是这样，从下到上的顺序：

首先是输入的图片(image)
经过一层卷积层 (convolution)
然后在用池化(pooling)方式处理卷积的信息（比如使用 max pooling 的方式）.
在经过一次同样的处理, 把得到的第二次处理的信息传入两层全连接的神经层 (fully connected),这也是一般的两层神经网络层
