#

图像分类是计算机视觉中最基础的任务，基本上深度学习模型的发展史就是图像分类任务提升的发展历史，不过图像分类并不是那么简单，也没有被完全解决。

1. 什么是图像分类

- 图像分类是计算机视觉中最基础的一个任务，也是几乎所有的基准模型进行比较的任务。从最开始比较简单的 10 分类的灰度图像手写数字识别任务 mnist，到后来更大一点的 10 分类的 cifar10 和 100 分类的 cifar100 任务，到后来的 imagenet 任务，图像分类模型伴随着数据集的增长，一步一步提升到了今天的水平。现在，在 imagenet 这样的超过 1000 万图像，超过 2 万类的数据集中，计算机的图像分类水准已经超过了人类。

- 不过，不要把图像分类任务想的过于简单。

- 图像分类顾名思义就是一个模式分类问题，它的目标是将不同的图像，划分到不同的类别，实现最小的分类误差。总体来说，对于单标签的图像分类问题，它可以分为跨物种语义级别的图像分类，子类细粒度图像分类，以及实例级图像分类三大类别。

**1.1 跨物种语义级别的图像分类 **

- 所谓跨物种语义级别的图像分类，它是在不同物种的层次上识别不同类别的对象，比较常见的包括如猫狗分类等。这样的图像分类，各个类别之间因为属于不同的物种或大类，往往具有较大的类间方差，而类内则具有较小的类内误差。

> cifar 包含 10 个类别，分别是 airplane，automobile，bird，cat，deer，dog，frog，horse，ship，truck，其中 airplane，automobile，ship，truck 都是交通工具，bird，cat，deer，dog，frog，horse 都是动物，可以认为是两个大的品类。而交通工具内部，动物内部，都是完全不同的物种，这些都是语义上完全可以区分的对象，所以 cifar10 的分类任务，可以看作是一个跨物种语义级别的图像分类问题。类间方差大，类内方差小。

**1.2 子类细粒度图像分类 **

- 细粒度图像分类，相对于跨物种的图像分类，级别更低一些。它往往是同一个大类中的子类的分类，如不同鸟类的分类，不同狗类的分类，不同车型的分类等。

> 从上图可以看出，两只鸟的纹理形状都很像，要像区分只能靠头部的颜色和纹理，所以要想训练出这样的分类器，就必须能够让分类器识别到这些区域，这是比跨物种语义级别的图像分类更难的问题。

**1.3 实例级图像分类 **

- 如果我们要区分不同的个体，而不仅仅是物种类或者子类，那就是一个识别问题，或者说是实例级别的图像分类，最典型的任务就是人脸识别。

- 在人脸识别任务中，需要鉴别一个人的身份，从而完成考勤等任务。人脸识别一直是计算机视觉里面的重大课题，虽然经历了几十年的发展，但仍然没有被完全解决，它的难点在于遮挡，光照，大姿态等经典难题，读者可以参考更多资料去学习。

2. 图像分类模型

- 图像分类任务从传统的方法到基于深度学习的方法，经历了几十年的发展。这里只关注于深度学习的进展，下面重点讲述几个重要的节点。

  2.1 MNIST 与 LeNet5

- 在计算机视觉分类算法的发展中，MNIST 是首个具有通用学术意义的基准。这是一个手写数字的分类标准，包含 60000 个训练数据，10000 个测试数据，图像均为灰度图，通用的版本大小为 28×28。

- 在上个世纪 90 年代末本世纪初，SVM and K-nearest neighbors 方法被使用的比较多，以 SVM 为代表的方法，可以将 MNIST 分类错误率降低到了 0.56%，彼时仍然超过以神经网络为代表的方法，即 LeNet 系列网络。LeNet 网络诞生于 1994 年，后经过多次的迭代才有了 1998 年的 LeNet5，是为我们所广泛知晓的版本。

- 这是一个经典的卷积神经网络，它包含着一些重要的特性，这些特性仍然是现在 CNN 网络的核心。

- 卷积层由卷积，池化，非线性激活函数构成。从 1998 年至今，经过 20 年的发展后，卷积神经网络依然遵循着这样的设计思想。其中，卷积发展出了很多的变种，池化则逐渐被带步长的卷积完全替代，非线性激活函数更是演变出了很多的变种。

- 稀疏连接，也就是局部连接，这是以卷积神经网络为代表的技术能够发展至今的最大前提。利用图像的局部相似性，这一区别于传统全连接的方式，推动了整个神经网络技术的发展。

- 虽然 LeNet5 当时的错误率仍然停留在 0.7%的水平，不如同时期最好的 SVM 方法，但随着网络结构的发展，神经网络方法很快就超过了其他所有方法，错误率也降低到了 0.23%，甚至有的方法已经达到了错误率接近 0 的水平。

**2.2 ImageNet 与 AlexNet **

在本世纪的早期，虽然神经网络开始有复苏的迹象，但是受限于数据集的规模和硬件的发展，神经网络的训练和优化仍然是非常困难的。MNIST 和 CIFAR 数据集都只有 60000 张图，这对于 10 分类这样的简单的任务来说，或许足够，但是如果想在工业界落地更加复杂的图像分类任务，仍然是远远不够的。

后来在李飞飞等人数年时间的整理下，2009 年，ImageNet 数据集发布了，并且从 2010 年开始每年举办一次 ImageNet 大规模视觉识别挑战赛，即 ILSVRC。ImageNet 数据集总共有 1400 多万幅图片，涵盖 2 万多个类别，在论文方法的比较中常用的是 1000 类的基准。

在 ImageNet 发布的早年里，仍然是以 SVM 和 Boost 为代表的分类方法占据优势，直到 2012 年 AlexNet 的出现。

AlexNet 是第一个真正意义上的深度网络，与 LeNet5 的 5 层相比，它的层数增加了 3 层，网络的参数量也大大增加，输入也从 28 变成了 224，同时 GPU 的面世，也使得深度学习从此进行 GPU 为王的训练时代。

AlexNet 有以下的特点：

网络比 LeNet5 更深，包括 5 个卷积层和 3 个全连接层。

使用 Relu 激活函数，收敛很快，解决了 Sigmoid 在网络较深时出现的梯度弥散问题。

加入了 Dropout 层，防止过拟合。

使用了 LRN 归一化层，对局部神经元的活动创建竞争机制，抑制反馈较小的神经元放大反应大的神经元，增强了模型的泛化能力。

使用裁剪翻转等操作做数据增强，增强了模型的泛化能力。预测时使用提取图片四个角加中间五个位置并进行左右翻转一共十幅图片的方法求取平均值，这也是后面刷比赛的基本使用技巧。

分块训练，当年的 GPU 计算能力没有现在强大，AlexNet 创新地将图像分为上下两块分别训练，然后在全连接层合并在一起。

总体的数据参数大概为 240M，远大于 LeNet5。

**2.3 分类模型的逐年进步 **

- 2013 年 ILSVRC 分类任务冠军网络是 Clarifai，不过更为我们熟知的是 zfnet。hinton 的学生 Zeiler 和 Fergus 在研究中利用反卷积技术引入了神经网络的可视化，对网络的中间特征层进行了可视化，为研究人员检验不同特征激活及其与输入空间的关系成为了可能。在这个指导下对 AlexNet 网络进行了简单改进，包括使用了更小的卷积核和步长，将 11x11 的卷积核变成 7x7 的卷积核，将 stride 从 4 变成了 2，性能超过了原始的 AlexNet 网络。

- 2014 年的冠亚军网络分别是 GoogLeNet 和 VGGNet。

- 其中 VGGNet 包括 16 层和 19 层两个版本，共包含参数约为 550M。全部使用 3×3 的卷积核和 2×2 的最大池化核，简化了卷积神经网络的结构。VGGNet 很好的展示了如何在先前网络架构的基础上通过简单地增加网络层数和深度就可以提高网络的性能。虽然简单，但是却异常的有效，在今天，VGGNet 仍然被很多的任务选为基准模型。

- GoogLeNet 是来自于 Google 的 Christian Szegedy 等人提出的 22 层的网络，其 top-5 分类错误率只有 6.7%。

- GoogleNet 的核心是 Inception Module，它采用并行的方式。一个经典的 inception 结构，包括有四个成分。1×1 卷积，3×3 卷积，5×5 卷积，3×3 最大池化，最后对四个成分运算结果进行通道上组合。这就是 Inception Module 的核心思想。通过多个卷积核提取图像不同尺度的信息然后进行融合，可以得到图像更好的表征。自此，深度学习模型的分类准确率已经达到了人类的水平(5%~10%)。

- 与 VGGNet 相比，GoogleNet 模型架构在精心设计的 Inception 结构下，模型更深又更小，计算效率更高。

- 2015 年，ResNet 获得了分类任务冠军。它以 3.57%的错误率表现超过了人类的识别水平，并以 152 层的网络架构创造了新的模型记录。由于 ResNet 采用了跨层连接的方式，它成功的缓解了深层神经网络中的梯度消散问题，为上千层的网络训练提供了可能。

- 2016 年依旧诞生了许多经典的模型，包括赢得分类比赛第二名的 ResNeXt，101 层的 ResNeXt 可以达到 ResNet152 的精确度，却在复杂度上只有后者的一半，核心思想为分组卷积。即首先将输入通道进行分组，经过若干并行分支的非线性变换，最后合并。

- 在 ResNet 基础上，密集连接的 DenseNet 在前馈过程中将每一层与其他的层都连接起来。对于每一层网络来说，前面所有网络的特征图都被作为输入，同时其特征图也都被后面的网络层作为输入所利用。

- DenseNet 中的密集连接还可以缓解梯度消失的问题，同时相比 ResNet，可以更强化特征传播和特征的复用，并减少了参数的数目。DenseNet 相较于 ResNet 所需的内存和计算资源更少，并达到更好的性能。

- 2017 年，也是 ILSVRC 图像分类比赛的最后一年，SeNet 获得了冠军。这个结构，仅仅使用了“特征重标定”的策略来对特征进行处理，通过学习获取每个特征通道的重要程度，根据重要性去降低或者提升相应的特征通道的权重。

- 至此，图像分类的比赛基本落幕，也接近算法的极限。但是，在实际的应用中，却面临着比比赛中更加复杂和现实的问题，需要大家不断积累经验。

3. 总结

- 虽然基本的图像分类任务，尤其是比赛趋近饱和，但是现实中的图像任务仍然有很多的困难和挑战。如类别不均衡的分类任务，类内方差非常大的细粒度分类任务，以及包含无穷负样本的分类任务。

- 不是所有的分类任务，样本的数量都是相同的，有很多任务，类别存在极大的不均衡问题，比如边缘检测任务。图像中的边缘像素，与非边缘像素，通常有 3 个数量级以上的差距，在这样的情况下，要很好的完成图像分类任务，必须在优化目标上进行设计。

- 虽然前面我们说过图像分类可以分为 3 大类，对于猫狗分类这样的语义级别的问题，算法已经达到或超越人类专家水平，但是对于如何区分不同种类的猫这样的细粒度分类问题，算法仅仅在某些数据集上勉强能突破 90%，远未超越人类专家，还有非常大的发展空间。

- 另外前面所说的分类，全部都是单标签分类问题，即每一个图只对应一个类别，而很多的任务，其实是多标签分类问题，一张图可以对应多个标签。多标签分类问题，通常有两种解决方案，即转换为多个单标签分类问题，或者直接联合研究。前者，可以训练多个分类器，来判断该维度属性的是否，损失函数常使用 softmax loss。后者，则直接训练一个多标签的分类器，所使用的标签为 0,1,0,0…这样的向量，使用 hanmming 距离等作为优化目标。

##

- 在对卷积的含义有了一定的理解之后，我们便可以对 CNN 在最简单的计算机视觉任务图像分类中的经典网络进行探索。CNN 在近几年的发展历程中，从经典的 LeNet5 网络到最近号称最好的图像分类网络 EfficientNet，大量学者不断的做出了努力和创新。本讲我们就来梳理经典的图像分类网络。

- 计算机视觉的三大任务

自从神经网络和深度学习方法引入到图像领域，经过近些年来的发展，从一开始的图像分类逐渐延伸到目标检测和图像分割领域，深度学习也逐渐在计算机视觉领域占据绝对的主导地位。如果要想利用深度学习技术开启计算机视觉领域的研究，明确并深刻理解计算机视觉的三大任务非常关键。计算机视觉三大任务如图 1 所示。

- 从图中我们可以简单描述计算机视觉三大任务的要义。图像分类就是要回答这张图像是一只猫的问题，跟传统的机器学习任务并无区别，只是我们的输入由数值数据变成图片数据。本节的内容就是介绍 CNN 在图像分类的发展历史上出现的一些经典的网络。

- 而目标检测则不仅需要回答图像中有什么，而且还得给出这些物体在图像中位置问题，以图中为例就是不仅要识别图中的猫和狗，还得给出猫和狗的具体定位。所以目标检测的任务简单而言就是分类+定位。在无人驾驶的应用中，我们的目标是训练出一个具有极高准确率的物体检测器，在工业产品的瑕疵检测中，我们的目标是能够快速准确的找出产品中的瑕疵区域，在医学肺部结节的检测中，我们的任务是能够根据病人肺部影像很好的检测出结节的位置。图 2 是一个自动驾驶场景下对于各个目标物体的检测和识别。

- 图像分割则是需要实现像素级的图像分割，以图中为例就是要把每个物体以像素级的标准分割开来，这对算法的要求则更高。图 3 就是一个定位和实例分割示例。

- CNN 图像分类发展史

##

背景介绍
图像相比文字能够提供更加生动、容易理解及更具艺术感的信息，是人们转递与交换信息的重要来源。在本教程中，我们专注于图像识别领域的一个重要问题，即图像分类。

图像分类是根据图像的语义信息将不同类别图像区分开来，是计算机视觉中重要的基本问题，也是图像检测、图像分割、物体跟踪、行为分析等其他高层视觉任务的基础。图像分类在很多领域有广泛应用，包括安防领域的人脸识别和智能视频分析等，交通领域的交通场景识别，互联网领域基于内容的图像检索和相册自动归类，医学领域的图像识别等。

一般来说，图像分类通过手工特征或特征学习方法对整个图像进行全部描述，然后使用分类器判别物体类别，因此如何提取图像的特征至关重要。在深度学习算法之前使用较多的是基于词袋(Bag of Words)模型的物体分类方法。词袋方法从自然语言处理中引入，即一句话可以用一个装了词的袋子表示其特征，袋子中的词为句子中的单词、短语或字。对于图像而言，词袋方法需要构建字典。最简单的词袋模型框架可以设计为底层特征抽取、特征编码、分类器设计三个过程。

而基于深度学习的图像分类方法，可以通过有监督或无监督的方式学习层次化的特征描述，从而取代了手工设计或选择图像特征的工作。深度学习模型中的卷积神经网络(Convolution Neural Network, CNN)近年来在图像领域取得了惊人的成绩，CNN 直接利用图像像素信息作为输入，最大程度上保留了输入图像的所有信息，通过卷积操作进行特征的提取和高层抽象，模型输出直接是图像识别的结果。这种基于"输入-输出"直接端到端的学习方法取得了非常好的效果，得到了广泛的应用。

本教程主要介绍图像分类的深度学习模型，以及如何使用 PaddlePaddle 训练 CNN 模型。

一个好的模型既要对不同类别识别正确，同时也应该能够对不同视角、光照、背景、变形或部分遮挡的图像正确识别(这里我们统一称作图像扰动)。图 3 展示了一些图像的扰动，较好的模型会像聪明的人类一样能够正确识别。

模型概览
图像识别领域大量的研究成果都是建立在 PASCAL VOC、ImageNet 等公开的数据集上，很多图像识别算法通常在这些数据集上进行测试和比较。PASCAL VOC 是 2005 年发起的一个视觉挑战赛，ImageNet 是 2010 年发起的大规模视觉识别竞赛(ILSVRC)的数据集，在本章中我们基于这些竞赛的一些论文介绍图像分类模型。

在 2012 年之前的传统图像分类方法可以用背景描述中提到的三步完成，但通常完整建立图像识别模型一般包括底层特征学习、特征编码、空间约束、分类器设计、模型融合等几个阶段。
  1). 底层特征提取: 通常从图像中按照固定步长、尺度提取大量局部特征描述。常用的局部特征包括 SIFT(Scale-Invariant Feature Transform, 尺度不变特征转换) [1]、HOG(Histogram of Oriented Gradient, 方向梯度直方图) [2]、LBP(Local Bianray Pattern, 局部二值模式) [3] 等，一般也采用多种特征描述子，防止丢失过多的有用信息。
  2). 特征编码: 底层特征中包含了大量冗余与噪声，为了提高特征表达的鲁棒性，需要使用一种特征变换算法对底层特征进行编码，称作特征编码。常用的特征编码包括向量量化编码 [4]、稀疏编码 [5]、局部线性约束编码 [6]、Fisher 向量编码 [7] 等。
  3). 空间特征约束: 特征编码之后一般会经过空间特征约束，也称作特征汇聚。特征汇聚是指在一个空间范围内，对每一维特征取最大值或者平均值，可以获得一定特征不变形的特征表达。金字塔特征匹配是一种常用的特征聚会方法，这种方法提出将图像均匀分块，在分块内做特征汇聚。
  4). 通过分类器分类: 经过前面步骤之后一张图像可以用一个固定维度的向量进行描述，接下来就是经过分类器对图像进行分类。通常使用的分类器包括 SVM(Support Vector Machine, 支持向量机)、随机森林等。而使用核方法的 SVM 是最为广泛的分类器，在传统图像分类任务上性能很好。

这种方法在 PASCAL VOC 竞赛中的图像分类算法中被广泛使用 [18]。NEC 实验室在 ILSVRC2010 中采用 SIFT 和 LBP 特征，两个非线性编码器以及 SVM 分类器获得图像分类的冠军 [8]。

Alex Krizhevsky 在 2012 年 ILSVRC 提出的 CNN 模型 [9] 取得了历史性的突破，效果大幅度超越传统方法，获得了 ILSVRC2012 冠军，该模型被称作 AlexNet。这也是首次将深度学习用于大规模图像分类中。从 AlexNet 之后，涌现了一系列 CNN 模型，不断地在 ImageNet 上刷新成绩，如图 4 展示。随着模型变得越来越深以及精妙的结构设计，Top-5 的错误率也越来越低，降到了 3.5%附近。而在同样的 ImageNet 数据集上，人眼的辨识错误率大概在 5.1%，也就是目前的深度学习模型的识别能力已经超过了人眼。
